---
date: 2013-03-27
layout: post
title: 并发编程之内存屏障
description: Memory Barriers/Fences 
categories:
- Blog
tags:
- Java
- Concurrent Programming
- 文章翻译

---

原文地址：http://mechanical-sympathy.blogspot.com/2011/07/memory-barriersfences.html 或 http://ifeve.com/memory-barriersfences/

本文我将和大家讨论并发编程中最基础的一项技术：内存屏障，也就是让一个处理单元中的内存状态对其它处理单元可见的一项技术。

CPU使用了很多技术来达成一个事实：CPU执行单元的速度要超过主存。在我上一篇文章 "Write Combing - 合并写"中我已经介绍了其中的一项技术。CPU避免内存访问延迟最常见的技术是将指令管道化，然后尽力重排这些管道的执行而把因为缓存未命中引起的延迟降到最小。

当一个程序执行时候指令是否被重排并不重要，只要最终的结果是一样的。例如，在一个循环里，如果循环体内没用到这个计数器，循环的计数器什么时候更新（在循环开始，中间还是最后）并不重要。编译器和CPU可以自由的重排指令以最佳的利用CPU在下一次循环前更新该计数器即可。并且在循环执行中，这个变量可能一直存在寄存器上，并没有被推出到缓存或主存，这样这个变量对其他CPU来说一直都是不可见的。

CPU核内部包含了多个执行单元。例如，现代Intel CPU包含了6个执行单元，可以组合进行算术运算，逻辑条件判断及内存操作。每个执行单元可以执行上述任务的某种组合。这些执行单元是并行执行的，这样指令也就是在并行执行。这也就产生了程序顺序的另一种不确定性，如果站在另一个CPU角度看。

最后，当一个缓存失效发生时，现代CPU可以先假设一个内存载入的值并根据这个假设值继续执行，知道内存载入返回确切的值。


<img src="http://ifeve.com/wp-content/uploads/2013/03/cpu.png"/>

代码顺序并不是真正的执行顺序，CPU和编译器可以各种优化只要有空间提高性能。缓存和主存的读取会利用load, store和write-combining缓冲区来缓冲和重排。这些缓冲区是查找速度很快的关联队列，当一个后来发生的load需要读取上一个store的值，而该值还没有到达缓存，查找是必需的，上图描绘的是一个简化的现代多核CPU，从上图可以看出执行单元可以利用本地寄存器和缓冲区来管理缓存子系统的交流。
